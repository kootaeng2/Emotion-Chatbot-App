# íŒŒì¼ ì´ë¦„: evaluate.py

import torch
import pandas as pd
# 'from pyexpat import model' ë¼ì¸ì€ ì™„ì „íˆ ì‚­ì œí•©ë‹ˆë‹¤.
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
import os
import json
import re
import platform
import matplotlib.pyplot as plt
import seaborn as sns

# --- Matplotlib í•œê¸€ í°íŠ¸ ì„¤ì • (ì´ì „ê³¼ ë™ì¼) ---
try:
    if platform.system() == 'Windows':
        plt.rc('font', family='Malgun Gothic')
    elif platform.system() == 'Darwin': # Mac OS
        plt.rc('font', family='AppleGothic')
    else: # Linux
        plt.rc('font', family='NanumBarunGothic')
    plt.rcParams['axes.unicode_minus'] = False
except:
    print("í•œê¸€ í°íŠ¸ ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê·¸ë˜í”„ì˜ ë¼ë²¨ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# --- í—¬í¼(Helper) í•¨ìˆ˜ ë° í´ë˜ìŠ¤ ì •ì˜ (ì´ì „ê³¼ ë™ì¼) ---
class EmotionDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels
    def __getitem__(self, idx):
        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)
        return item
    def __len__(self):
        return len(self.labels)

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    acc = accuracy_score(labels, preds)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)
    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}

# --- train_final.pyì™€ ë™ì¼í•œ ë°ì´í„° ì²˜ë¦¬ ë¡œì§ ì „ì²´ë¥¼ ì—¬ê¸°ì— ì¶”ê°€ ---
def map_ecode_to_major_emotion(ecode):
    """Eì½”ë“œë¥¼ ëŒ€ë¶„ë¥˜ ê°ì •ìœ¼ë¡œ ë§¤í•‘í•˜ëŠ” í•¨ìˆ˜"""
    try:
        code_num = int(ecode[1:])
    except (ValueError, TypeError):
        return None
    
    # ì´ ë¶€ë¶„ì€ train_final.pyì™€ ì™„ì „íˆ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤.
    if 10 <= code_num <= 19: return 'ë¶„ë…¸'
    elif 20 <= code_num <= 29: return 'ìŠ¬í””'
    elif 30 <= code_num <= 39: return 'ë¶ˆì•ˆ'
    elif 40 <= code_num <= 49: return 'ìƒì²˜'
    elif 50 <= code_num <= 59: return 'ë‹¹í™©'
    elif 60 <= code_num <= 69: return 'ê¸°ì¨'
    else: return None

def load_and_process_validation_data(file_path='./data/'):
    """JSONì„ ë¡œë“œí•˜ê³  ë ˆì´ë¸”ì„ í†µí•©/ì²˜ë¦¬í•˜ëŠ” ì™„ì „í•œ í•¨ìˆ˜"""
    val_label_path = os.path.join(file_path, 'validation-label.json')
    try:
        with open(val_label_path, 'r', encoding='utf-8') as f:
            validation_data_raw = json.load(f)
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: í‰ê°€ìš© ë¼ë²¨ íŒŒì¼ '{val_label_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
        
    data = [{'text': " ".join(d['talk']['content'].values()), 'emotion': d['profile']['emotion']['type']} for d in validation_data_raw]
    df_val = pd.DataFrame(data)

    df_val['major_emotion'] = df_val['emotion'].apply(map_ecode_to_major_emotion)
    df_val.dropna(subset=['major_emotion'], inplace=True)
    
    def clean_text(text):
        return re.sub(r'[^ê°€-í£a-zA-Z0-9 ]', '', text)
    df_val['cleaned_text'] = df_val['text'].apply(clean_text)
    
    return df_val

# --- ë©”ì¸ í‰ê°€ ë¡œì§ ---
def evaluate_saved_model():
    """ì €ì¥ëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ ì„±ëŠ¥ í‰ê°€ ë° í˜¼ë™ í–‰ë ¬ì„ ìƒì„±í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""
    
    MODEL_PATH = "./results/emotion_model_final"  # ê²½ë¡œëŠ” results1ìœ¼ë¡œ ìœ ì§€
    print(f"'{MODEL_PATH}' ê²½ë¡œì˜ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤.")

    try:
        tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
        loaded_model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)
        loaded_model.config.problem_type = "single_label_classification"
    except OSError:
        print(f"ì˜¤ë¥˜: '{MODEL_PATH}' ê²½ë¡œì—ì„œ ëª¨ë¸ ë˜ëŠ” í† í¬ë‚˜ì´ì €ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    df_val = load_and_process_validation_data()
    if df_val is None or df_val.empty: 
        print("ì²˜ë¦¬ í›„ í‰ê°€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # --- ğŸ‘‡ğŸ‘‡ğŸ‘‡ ë¯¸ì •ì˜ ë³€ìˆ˜ë“¤ì„ ì—¬ê¸°ì„œ ì •ì˜í•©ë‹ˆë‹¤ ğŸ‘‡ğŸ‘‡ğŸ‘‡ ---
    label2id = loaded_model.config.label2id
    id2label = loaded_model.config.id2label

    df_val['label_id'] = df_val['major_emotion'].map(label2id)
    df_val.dropna(subset=['label_id'], inplace=True)

    val_labels = df_val['label_id'].tolist()
    val_texts = df_val['cleaned_text'].tolist()
    
    val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128, return_tensors="pt")
    # --- ğŸ‘†ğŸ‘†ğŸ‘† ë³€ìˆ˜ ì •ì˜ ì™„ë£Œ ğŸ‘†ğŸ‘†ğŸ‘† ---
    
    val_dataset = EmotionDataset(val_encodings, val_labels)

    training_args = TrainingArguments(
        output_dir="./results1/temp_eval",
        report_to="none"
    )

    trainer = Trainer(
        model=loaded_model, 
        args=training_args,
        compute_metrics=compute_metrics
    )

    print("í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    results = trainer.evaluate(eval_dataset=val_dataset)
    print("\n--- ìµœì¢… í‰ê°€ ê²°ê³¼ ---")
    print(results)
    
    print("\n--- í˜¼ë™ í–‰ë ¬ ìƒì„± ---")
    predictions = trainer.predict(val_dataset)
    y_pred = predictions.predictions.argmax(-1)
    y_true = predictions.label_ids

    labels = [id2label[i] for i in sorted(id2label.keys())]
    cm = confusion_matrix(y_true, y_pred)
    
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
    plt.xlabel('ì˜ˆì¸¡ ë¼ë²¨ (Predicted Label)')
    plt.ylabel('ì‹¤ì œ ë¼ë²¨ (True Label)')
    plt.title('Confusion Matrix')
    
    cm_path = os.path.join(MODEL_PATH, "confusion_matrix.png")
    plt.savefig(cm_path)
    print(f"í˜¼ë™ í–‰ë ¬ì´ {cm_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
if __name__ == "__main__":
    evaluate_saved_model()